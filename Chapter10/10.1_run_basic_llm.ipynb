{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc3169-7a30-4441-a93c-1fd546c413fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This recipe requires a HuggingFace token to access the mistral models from the hub. You will need to create a HuggingFace login\n",
    "# and generate a token for use at https://huggingface.co/settings/tokens. You will also need to visit the model card at \n",
    "# https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3 and accept the terms to use the model. Once you have generated the token,\n",
    "# save it in an environment variable named HUGGINGFACE_TOKEN and read it in the recipe as shown in the snippet below.\n",
    "from huggingface_hub import login\n",
    "hf_token = os.environ.get('HUGGINGFACE_TOKEN')\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735e96ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"XPU available:\", torch.xpu.is_available())\n",
    "print(\"Device count:\", torch.xpu.device_count())\n",
    "\n",
    "if torch.xpu.is_available():\n",
    "    print(\"Device name:\", torch.xpu.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43041e-5f81-4b31-b90f-257e39a3b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"xpu\" if torch.xpu.is_available() else \"cpu\")\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                         bnb_4bit_use_double_quant=True,\n",
    "                                         bnb_4bit_quant_type= \"nf4\"\n",
    "                                         )\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"mistralai/Mistral-7B-v0.3\", \n",
    "            device_map=\"auto\", \n",
    "            quantization_config=quantization_config,\n",
    "        )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.3\", padding_side=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c45b7fb-b33f-4d80-a36b-e2331b49ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    num_beams=4,\n",
    "    early_stopping=True,\n",
    "    eos_token_id=model.config.eos_token_id,\n",
    "    pad_token_id=model.config.eos_token_id,\n",
    "    max_new_tokens=900,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02febbf4-ed87-455f-ac2d-b7b78aa3b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_sentence = \"Step by step way on how to make an apple pie:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485356eb-adb1-48fd-ba14-aace7f937e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer([seed_sentence], return_tensors=\"pt\").to(device)\n",
    "generated_ids = model.generate(**model_inputs, generation_config=generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d6293-f967-49eb-b374-be448ffedf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_tokens = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(generated_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_cookbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
